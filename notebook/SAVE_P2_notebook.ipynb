{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46f35bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows 11\\Desktop\\AI_Engineer\\Projet_2_Requetez_des_services_IA\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c4d22",
   "metadata": {},
   "source": [
    "## 1. Configuration Initiale et Importations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bf121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47174ae2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#from PIL import Image\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "#from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm \n",
    "from tqdm.notebook import tqdm\n",
    "import base64\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ba04a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      2\u001b[39m load_dotenv(dotenv_path=\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWindows 11\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mAI_Engineer\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mProjet_2_Requetez_des_services_IA\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.venv\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.env\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m api_key = \u001b[43mos\u001b[49m.getenv(\u001b[33m\"\u001b[39m\u001b[33mAPI_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# print les 5 dernier digit de la clé\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key:\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\Windows 11\\Desktop\\AI_Engineer\\Projet_2_Requetez_des_services_IA\\.venv\\.env\")\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "# print les 5 dernier digit de la clé\n",
    "if api_key:\n",
    "    api_token = api_key\n",
    "    print(f\"API Key chargée : {api_key[:5]}***\")  # masque pour affichage\n",
    "else:\n",
    "    api_token = None\n",
    "    print(\"API Key non trouvée. Vérifiez le fichier .env et la variable 'api_token'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eabdfd",
   "metadata": {},
   "source": [
    "## 2. API d'Inférence Hugging Face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a006a0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      3\u001b[39m load_dotenv()  \u001b[38;5;66;03m# .env automatiquement trouvé à la racine du projet\u001b[39;00m\n\u001b[32m      5\u001b[39m api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mAPI_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # .env automatiquement trouvé à la racine du projet\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "if api_key:\n",
    "    api_token = api_key\n",
    "    print(f\"API Key chargée : {api_key[:5]}***\")  # masque pour affichage des 5 premières caractères)\n",
    "else:\n",
    "    api_token = None\n",
    "    print(\"API Key non trouvée. Vérifiez le fichier .env et la variable 'api_token'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4309de",
   "metadata": {},
   "source": [
    "test site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b912eb",
   "metadata": {},
   "source": [
    "## 3. Fonctions Utilitaires pour le Traitement des Masques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import base64\n",
    "import io\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAPPAGE DES CLASSES ET COULEURS\n",
    "# ============================================================================\n",
    "\n",
    "# Mappage classe anglaise -> ID numérique (tel que retourné par l'API)\n",
    "CLASS_MAPPING = {\n",
    "    \"Background\": 0,\n",
    "    \"Hat\": 1,\n",
    "    \"Hair\": 2,\n",
    "    \"Sunglasses\": 3,\n",
    "    \"Upper-clothes\": 4,\n",
    "    \"Skirt\": 5,\n",
    "    \"Pants\": 6,\n",
    "    \"Dress\": 7,\n",
    "    \"Belt\": 8,\n",
    "    \"Left-shoe\": 9,\n",
    "    \"Right-shoe\": 10,\n",
    "    \"Face\": 11,\n",
    "    \"Left-leg\": 12,\n",
    "    \"Right-leg\": 13,\n",
    "    \"Left-arm\": 14,\n",
    "    \"Right-arm\": 15,\n",
    "    \"Bag\": 16,\n",
    "    \"Scarf\": 17\n",
    "}\n",
    "\n",
    "# Mappage anglais -> français pour l'affichage de la légende\n",
    "CLASS_NAMES_FRENCH = {\n",
    "    \"Background\": \"Arrière-plan\",\n",
    "    \"Hat\": \"Chapeau\",\n",
    "    \"Hair\": \"Cheveux\",\n",
    "    \"Sunglasses\": \"Lunettes de soleil\",\n",
    "    \"Upper-clothes\": \"Haut (vêtement)\",\n",
    "    \"Skirt\": \"Jupe\",\n",
    "    \"Pants\": \"Pantalon\",\n",
    "    \"Dress\": \"Robe\",\n",
    "    \"Belt\": \"Ceinture\",\n",
    "    \"Left-shoe\": \"Chaussure gauche\",\n",
    "    \"Right-shoe\": \"Chaussure droite\",\n",
    "    \"Face\": \"Visage\",\n",
    "    \"Left-leg\": \"Jambe gauche\",\n",
    "    \"Right-leg\": \"Jambe droite\",\n",
    "    \"Left-arm\": \"Bras gauche\",\n",
    "    \"Right-arm\": \"Bras droit\",\n",
    "    \"Bag\": \"Sac\",\n",
    "    \"Scarf\": \"Écharpe\"\n",
    "}\n",
    "\n",
    "COLOR_MAPPING = {\n",
    "    0: (0, 0, 0),\n",
    "    1: (255, 255, 0),\n",
    "    2: (255, 165, 0),\n",
    "    3: (255, 0, 255),\n",
    "    4: (255, 0, 0),\n",
    "    5: (255, 255, 0),\n",
    "    6: (0, 128, 0),\n",
    "    7: (0, 0, 255),\n",
    "    8: (128, 0, 128),\n",
    "    9: (255, 255, 0),\n",
    "    10: (0, 0, 255),\n",
    "    11: (135, 206, 235),\n",
    "    12: (173, 216, 230),\n",
    "    13: (173, 216, 230),\n",
    "    14: (173, 216, 230),\n",
    "    15: (173, 216, 230),\n",
    "    16: (255, 165, 0),\n",
    "    17: (128, 0, 128)\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTIONS UTILITAIRES\n",
    "# ============================================================================\n",
    "\n",
    "def get_image_dimensions(img_path):\n",
    "    \"\"\"Récupère les dimensions (largeur, hauteur) d'une image.\"\"\"\n",
    "    original_image = Image.open(img_path)\n",
    "    return original_image.size\n",
    "\n",
    "\n",
    "def decode_base64_mask(base64_string, width, height):\n",
    "    \"\"\"Décode un masque encodé en base64 en tableau NumPy.\"\"\"\n",
    "    mask_data = base64.b64decode(base64_string)\n",
    "    mask_image = Image.open(io.BytesIO(mask_data))\n",
    "    mask_array = np.array(mask_image)\n",
    "    if len(mask_array.shape) == 3:\n",
    "        mask_array = mask_array[:, :, 0]\n",
    "    mask_image = Image.fromarray(mask_array).resize((width, height), Image.NEAREST)\n",
    "    return np.array(mask_image)\n",
    "\n",
    "\n",
    "def create_masks(results, width, height):\n",
    "    \"\"\"\n",
    "    Combine les masques de plusieurs classes en un seul masque.\n",
    "    \n",
    "    IMPORTANT: L'ordre d'application est crucial:\n",
    "    - Initialiser avec Background (0)\n",
    "    - Appliquer NON-background en premier\n",
    "    - Appliquer Background en dernier\n",
    "    \"\"\"\n",
    "    combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Afficher les classes détectées pour déboguer\n",
    "    print(f\"    Classes détectées: {[r['label'] for r in results]}\")\n",
    "\n",
    "    # Traiter les masques non-Background en premier\n",
    "    for result in results:\n",
    "        label = result['label']\n",
    "        class_id = CLASS_MAPPING.get(label, 0)\n",
    "        if class_id == 0:\n",
    "            continue\n",
    "        \n",
    "        mask_array = decode_base64_mask(result['mask'], width, height)\n",
    "        pixels_assigned = np.count_nonzero(mask_array)\n",
    "        print(f\"    {label} (ID={class_id}): {pixels_assigned} pixels\")\n",
    "        combined_mask[mask_array > 0] = class_id\n",
    "\n",
    "    # Traiter Background en dernier\n",
    "    for result in results:\n",
    "        if result['label'] == 'Background':\n",
    "            mask_array = decode_base64_mask(result['mask'], width, height)\n",
    "            pixels_assigned = np.count_nonzero(mask_array)\n",
    "            print(f\"    Background (ID=0): {pixels_assigned} pixels\")\n",
    "            # Ne pas écraser les classes déjà assignées\n",
    "            combined_mask[(combined_mask == 0) & (mask_array > 0)] = 0\n",
    "\n",
    "    return combined_mask\n",
    "\n",
    "\n",
    "def colorize_segmentation_mask(mask_array):\n",
    "    \"\"\"Convertit un masque en niveaux de gris en image RGB colorisée.\"\"\"\n",
    "    height, width = mask_array.shape\n",
    "    colored_mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    for class_id, color_rgb in COLOR_MAPPING.items():\n",
    "        class_mask = (mask_array == class_id)\n",
    "        colored_mask[class_mask] = color_rgb\n",
    "\n",
    "    return colored_mask\n",
    "\n",
    "\n",
    "def create_overlay(original_img, colored_mask, alpha=0.6):\n",
    "    \"\"\"\n",
    "    Crée une superposition du masque colorisé sur l'image originale.\n",
    "    \n",
    "    Args:\n",
    "        original_img: Image PIL originale\n",
    "        colored_mask: Array NumPy RGB du masque colorisé\n",
    "        alpha: Transparence du masque (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        Image PIL de la superposition\n",
    "    \"\"\"\n",
    "    # Redimensionner original_img si nécessaire\n",
    "    if original_img.size != (colored_mask.shape[1], colored_mask.shape[0]):\n",
    "        original_img = original_img.resize(\n",
    "            (colored_mask.shape[1], colored_mask.shape[0]),\n",
    "            Image.Resampling.LANCZOS\n",
    "        )\n",
    "    \n",
    "    # Convertir original_img en array\n",
    "    original_array = np.array(original_img, dtype=np.float32)\n",
    "    colored_mask_float = colored_mask.astype(np.float32)\n",
    "    \n",
    "    # Appliquer l'overlay avec alpha blending\n",
    "    overlay = (1 - alpha) * original_array + alpha * colored_mask_float\n",
    "    overlay = overlay.astype(np.uint8)\n",
    "    \n",
    "    return Image.fromarray(overlay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b07a35",
   "metadata": {},
   "source": [
    "## 4. Segmentation d'une Seule Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a669a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_token}\"\n",
    "}\n",
    " \n",
    "\n",
    "if image_paths:\n",
    "    single_image_path = image_paths[0] # Prenons la première image de notre liste\n",
    "    print(f\"Traitement de l'image : {single_image_path}\")\n",
    "\n",
    "    try:\n",
    "        # Lire l'image en binaire\n",
    "        with open(single_image_path, \"rb\") as f:\n",
    "            image_data = f.read()\n",
    "       \n",
    "        \n",
    "\n",
    "        # Maintenant, utilisé l'API huggingface\n",
    "        response = requests.post(\n",
    "            API_URL, \n",
    "            headers={**headers, \"Content-Type\": \"image/png\"}, \n",
    "            data=image_data)\n",
    "        response.raise_for_status()  # Vérifie si la requête a réussi\n",
    "        # ainsi que les fonctions données plus haut pour ségmenter vos images.\n",
    "        results = response.json()\n",
    "        print(\"Réponse brute de l'API :\")\n",
    "        print(results)\n",
    "\n",
    "        width, height = get_image_dimensions(single_image_path)\n",
    "        masks = create_masks(results, width, height)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue : {e}\")\n",
    "else:\n",
    "    print(\"Aucune image à traiter. Vérifiez la configuration de 'image_dir' et 'max_images'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f338d811",
   "metadata": {},
   "source": [
    "## 5. Segmentation de Plusieurs Images (Batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_images_batch(list_of_image_paths, max_api_calls=50, delay_between_calls=1):\n",
    "    \"\"\"\n",
    "    Segmente une liste d'images en utilisant l'API Hugging Face avec gestion robuste.\n",
    "    \n",
    "    Cette fonction traite les images de manière séquentielle en appelant l'API\n",
    "    d'inférence Hugging Face. Elle implémente:\n",
    "    - Une limite de requêtes API pour éviter les surcharges (max 50 par défaut)\n",
    "    - Un délai entre les appels pour respecter les rate limits de l'API\n",
    "    - Une gestion d'exceptions exhaustive pour chaque type d'erreur\n",
    "    - Un logging détaillé de chaque étape du traitement\n",
    "    \n",
    "    Args:\n",
    "        list_of_image_paths (list): Liste des chemins vers les images PNG à segmenter.\n",
    "        max_api_calls (int): Nombre maximum d'appels API autorisés (défaut: 50).\n",
    "                            Les images au-delà de cette limite seront ignorées.\n",
    "        delay_between_calls (int): Délai en secondes entre chaque appel API (défaut: 1).\n",
    "                                  Augmenter cette valeur si vous rencontrez des\n",
    "                                  erreurs 429 (Too Many Requests).\n",
    "    \n",
    "    Returns:\n",
    "        list: Liste de masques de segmentation (numpy arrays uint8) correspondant\n",
    "              aux images traitées. Contient None pour les images non traitées\n",
    "              ou en cas d'erreur. La liste a la même longueur que list_of_image_paths.\n",
    "    \n",
    "    Levées:\n",
    "        Aucune exception n'est levée. Les erreurs sont capturées et loggées.\n",
    "        Chaque image problématique est enregistrée comme None dans la liste retournée.\n",
    "    \n",
    "    Exemple:\n",
    "        >>> chemins = ['img1.png', 'img2.png', 'img3.png']\n",
    "        >>> resultats = segment_images_batch(chemins, max_api_calls=50, delay_between_calls=1)\n",
    "        >>> print(len(resultats))  # 3\n",
    "    \"\"\"\n",
    "    batch_seg_results = []\n",
    "    total_images = len(list_of_image_paths)\n",
    "    api_calls_made = 0\n",
    "    images_skipped = 0\n",
    "\n",
    "    print(f\"Limite d'appels API: {max_api_calls}\")\n",
    "    print(f\"Délai entre appels: {delay_between_calls}s\\n\")\n",
    "\n",
    "    for idx, img_path in enumerate(list_of_image_paths, 1):\n",
    "        \n",
    "        # Vérifier la limite d'appels API\n",
    "        if api_calls_made >= max_api_calls:\n",
    "            print(f\"[{idx}/{total_images}] LIMITE ATTEINTE - Image ignorée\")\n",
    "            batch_seg_results.append(None)\n",
    "            images_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        print(f\"[{idx}/{total_images}] {os.path.basename(img_path)}\")\n",
    "        \n",
    "        try:\n",
    "            # Étape 1: Lire le fichier image\n",
    "            if not os.path.exists(img_path):\n",
    "                raise FileNotFoundError(f\"Fichier introuvable: {img_path}\")\n",
    "            \n",
    "            with open(img_path, \"rb\") as f:\n",
    "                image_data = f.read()\n",
    "            \n",
    "            # Étape 2: Envoyer requête POST à l'API HF\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    API_URL,\n",
    "                    headers={**headers, \"Content-Type\": \"image/png\"},\n",
    "                    data=image_data,\n",
    "                    timeout=30\n",
    "                )\n",
    "                api_calls_made += 1\n",
    "                \n",
    "            except requests.exceptions.Timeout:\n",
    "                raise TimeoutError(\"Timeout: L'API n'a pas répondu dans les 30 secondes\")\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                raise ConnectionError(\"Erreur de connexion: Impossible de joindre l'API\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                raise RuntimeError(f\"Erreur requête HTTP: {str(e)}\")\n",
    "            \n",
    "            # Étape 3: Vérifier le statut HTTP\n",
    "            if response.status_code == 429:\n",
    "                raise RuntimeError(\"Rate limit atteint (429). Augmentez delay_between_calls\")\n",
    "            elif response.status_code == 401:\n",
    "                raise RuntimeError(\"Authentification échouée (401). Vérifiez votre token API\")\n",
    "            elif response.status_code == 503:\n",
    "                raise RuntimeError(\"Service indisponible (503). Réessayez plus tard\")\n",
    "            elif not response.ok:\n",
    "                raise RuntimeError(f\"Erreur HTTP {response.status_code}: {response.text[:100]}\")\n",
    "            \n",
    "            # Étape 4: Parser la réponse JSON\n",
    "            try:\n",
    "                results = response.json()\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Réponse API invalide (non-JSON)\")\n",
    "            \n",
    "            # Étape 5: Créer le masque combiné\n",
    "            width, height = get_image_dimensions(img_path)\n",
    "            segmentation_mask = create_masks(results, width, height)\n",
    "            batch_seg_results.append(segmentation_mask)\n",
    "            print(f\"    Succès: {width}x{height} pixels\\n\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"    Erreur fichier: {e}\\n\")\n",
    "            batch_seg_results.append(None)\n",
    "        except TimeoutError as e:\n",
    "            print(f\"    Erreur timeout: {e}\\n\")\n",
    "            batch_seg_results.append(None)\n",
    "        except ConnectionError as e:\n",
    "            print(f\"    Erreur connexion: {e}\\n\")\n",
    "            batch_seg_results.append(None)\n",
    "        except ValueError as e:\n",
    "            print(f\"    Erreur parsing: {e}\\n\")\n",
    "            batch_seg_results.append(None)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"    Erreur API: {e}\\n\")\n",
    "            batch_seg_results.append(None)\n",
    "        except Exception as e:\n",
    "            print(f\"    Erreur inattendue: {str(e)[:100]}\\n\")\n",
    "            batch_seg_results.append(None)\n",
    "\n",
    "        # Délai entre les appels\n",
    "        time.sleep(delay_between_calls)\n",
    "\n",
    "    # Résumé du traitement\n",
    "    print(\"=\"*60)\n",
    "    print(f\"RÉSUMÉ DU TRAITEMENT:\")\n",
    "    print(f\"  Images traitées: {api_calls_made}\")\n",
    "    print(f\"  Appels API effectués: {api_calls_made}/{max_api_calls}\")\n",
    "    print(f\"  Images ignorées (limite): {images_skipped}\")\n",
    "    print(f\"  Images en erreur: {sum(1 for r in batch_seg_results if r is None)}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    return batch_seg_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc11138",
   "metadata": {},
   "source": [
    "## 6. Affichage des Résultats en Batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_segmented_images_batch(original_image_paths, segmentation_masks):\n",
    "    \"\"\"\n",
    "    Affiche: Image originale | Masque colorisé + Légende | Superposition + Légende.\n",
    "    Légende intégrée dans les images sans bordure, en transparence 100% et texte blanc.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not original_image_paths or not segmentation_masks:\n",
    "        print(\"Listes vides.\")\n",
    "        return\n",
    "    \n",
    "    valid_pairs = []\n",
    "    \n",
    "    for img_path, mask_array in zip(original_image_paths, segmentation_masks):\n",
    "        if mask_array is None or not os.path.exists(img_path):\n",
    "            continue\n",
    "        \n",
    "        original_img = Image.open(img_path)\n",
    "        if original_img.mode != 'RGB':\n",
    "            original_img = original_img.convert('RGB')\n",
    "        \n",
    "        valid_pairs.append((img_path, original_img, mask_array))\n",
    "    \n",
    "    if not valid_pairs:\n",
    "        print(\"Aucune paire valide.\")\n",
    "        return\n",
    "    \n",
    "    valid_count = len(valid_pairs)\n",
    "    fig = plt.figure(figsize=(20, valid_count * 6))\n",
    "    \n",
    "    # Créer la légende une fois (sans \"Arrière-plan\")\n",
    "    legend_elements = []\n",
    "    for class_name_en in sorted(CLASS_MAPPING.keys()):\n",
    "        # Filtrer \"Background\" (Arrière-plan)\n",
    "        if class_name_en == \"Background\":\n",
    "            continue\n",
    "        \n",
    "        class_id = CLASS_MAPPING[class_name_en]\n",
    "        class_name_fr = CLASS_NAMES_FRENCH.get(class_name_en, class_name_en)\n",
    "        color_rgb = tuple(c / 255.0 for c in COLOR_MAPPING[class_id])\n",
    "        legend_elements.append(\n",
    "            mpatches.Patch(facecolor=color_rgb, edgecolor='black', linewidth=0.8,\n",
    "                          label=class_name_fr)\n",
    "        )\n",
    "    \n",
    "    for row_idx, (img_path, original_img, mask_array) in enumerate(valid_pairs):\n",
    "        \n",
    "        # Colonne 1: Image originale\n",
    "        ax1 = plt.subplot(valid_count, 3, row_idx * 3 + 1)\n",
    "        ax1.imshow(original_img)\n",
    "        ax1.set_title(\"Image originale\", fontsize=12, fontweight='bold')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Colonne 2: Masque colorisé + Légende intégrée\n",
    "        colored_mask = colorize_segmentation_mask(mask_array)\n",
    "        ax2 = plt.subplot(valid_count, 3, row_idx * 3 + 2)\n",
    "        ax2.imshow(colored_mask)\n",
    "        ax2.set_title(\"Masque colorisé\", fontsize=12, fontweight='bold')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # Légende intégrée sans bordure en transparence 100%\n",
    "        legend2 = ax2.legend(handles=legend_elements, loc='upper left', fontsize=8, \n",
    "                            frameon=False,  # Pas de bordure\n",
    "                            framealpha=1.0,  # Transparence 100%\n",
    "                            bbox_to_anchor=(0.02, 0.98))\n",
    "        \n",
    "        # Changer la couleur du texte en blanc\n",
    "        for text in legend2.get_texts():\n",
    "            text.set_color('white')\n",
    "        \n",
    "        # Colonne 3: Superposition + Légende intégrée\n",
    "        overlay_img = create_overlay(original_img, colored_mask, alpha=0.5)\n",
    "        ax3 = plt.subplot(valid_count, 3, row_idx * 3 + 3)\n",
    "        ax3.imshow(overlay_img)\n",
    "        ax3.set_title(\"Superposition\", fontsize=12, fontweight='bold')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        # Légende intégrée sans bordure en transparence 100%\n",
    "        legend3 = ax3.legend(handles=legend_elements, loc='upper left', fontsize=8, \n",
    "                            frameon=False,  # Pas de bordure\n",
    "                            framealpha=1.0,  # Transparence 100%\n",
    "                            bbox_to_anchor=(0.02, 0.98))\n",
    "        \n",
    "        # Changer la couleur du texte en blanc\n",
    "        for text in legend3.get_texts():\n",
    "            text.set_color('white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# EXÉCUTION\n",
    "# ============================================================================\n",
    "\n",
    "if image_paths:\n",
    "    print(f\"Traitement de {len(image_paths)} image(s)...\\n\")\n",
    "    batch_seg_results = segment_images_batch(\n",
    "        image_paths,\n",
    "        max_api_calls=50,      # Limite à 50 appels API\n",
    "        delay_between_calls=1   # 1 seconde entre chaque appel (ou 3 si vous préférez)\n",
    "    )\n",
    "    print(\"Affichage des résultats...\\n\")\n",
    "    display_segmented_images_batch(image_paths, batch_seg_results)\n",
    "else:\n",
    "    print(\"Aucune image trouvée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e21ea",
   "metadata": {},
   "source": [
    "# 7. Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SYSTÈME D'ÉVALUATION DU MODÈLE - SEGFORMER B3 CLOTHES\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Évaluation du Modèle: sayeed99/segformer_b3_clothes\n",
    "Source: https://huggingface.co/sayeed99/segformer_b3_clothes\n",
    "\n",
    "Métriques Officielles HF:\n",
    "  - Mean IoU: 0.69\n",
    "  - Mean Accuracy: 0.80\n",
    "  - Evaluation Loss: 0.15\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score, accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    Classe pour évaluer les performances du modèle SegFormer B3.\n",
    "    Compare les résultats avec les benchmarks officiels HF.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Métriques officielles du modèle depuis HuggingFace\n",
    "    OFFICIAL_METRICS_BY_CLASS = {\n",
    "        0: {\"name\": \"Background\", \"accuracy\": 0.99, \"iou\": 0.99},\n",
    "        1: {\"name\": \"Hat\", \"accuracy\": 0.73, \"iou\": 0.68},\n",
    "        2: {\"name\": \"Hair\", \"accuracy\": 0.91, \"iou\": 0.82},\n",
    "        3: {\"name\": \"Sunglasses\", \"accuracy\": 0.73, \"iou\": 0.63},\n",
    "        4: {\"name\": \"Upper-clothes\", \"accuracy\": 0.87, \"iou\": 0.78},\n",
    "        5: {\"name\": \"Skirt\", \"accuracy\": 0.76, \"iou\": 0.65},\n",
    "        6: {\"name\": \"Pants\", \"accuracy\": 0.90, \"iou\": 0.84},\n",
    "        7: {\"name\": \"Dress\", \"accuracy\": 0.74, \"iou\": 0.55},\n",
    "        8: {\"name\": \"Belt\", \"accuracy\": 0.35, \"iou\": 0.30},\n",
    "        9: {\"name\": \"Left-shoe\", \"accuracy\": 0.74, \"iou\": 0.58},\n",
    "        10: {\"name\": \"Right-shoe\", \"accuracy\": 0.75, \"iou\": 0.60},\n",
    "        11: {\"name\": \"Face\", \"accuracy\": 0.92, \"iou\": 0.85},\n",
    "        12: {\"name\": \"Left-leg\", \"accuracy\": 0.90, \"iou\": 0.82},\n",
    "        13: {\"name\": \"Right-leg\", \"accuracy\": 0.90, \"iou\": 0.81},\n",
    "        14: {\"name\": \"Left-arm\", \"accuracy\": 0.86, \"iou\": 0.74},\n",
    "        15: {\"name\": \"Right-arm\", \"accuracy\": 0.82, \"iou\": 0.73},\n",
    "        16: {\"name\": \"Bag\", \"accuracy\": 0.91, \"iou\": 0.84},\n",
    "        17: {\"name\": \"Scarf\", \"accuracy\": 0.63, \"iou\": 0.29},\n",
    "    }\n",
    "    \n",
    "    OFFICIAL_OVERALL_METRICS = {\n",
    "        \"mean_accuracy\": 0.80,\n",
    "        \"mean_iou\": 0.69,\n",
    "        \"evaluation_loss\": 0.15,\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialise l'évaluateur du modèle.\"\"\"\n",
    "        self.evaluation_results = {\n",
    "            \"by_class\": {},\n",
    "            \"overall\": {},\n",
    "        }\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CALCUL DES MÉTRIQUES\n",
    "    # =========================================================================\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_iou(mask_pred, mask_true):\n",
    "        \"\"\"\n",
    "        Calcule l'IoU (Intersection over Union) pour une classe.\n",
    "        \n",
    "        IoU = |Intersection| / |Union|\n",
    "        Metrique standard pour la segmentation d'images.\n",
    "        \n",
    "        Args:\n",
    "            mask_pred (np.ndarray): Masque prédiction binaire\n",
    "            mask_true (np.ndarray): Masque vérité terrain binaire\n",
    "            \n",
    "        Returns:\n",
    "            float: Score IoU entre 0 et 1\n",
    "        \"\"\"\n",
    "        try:\n",
    "            iou = jaccard_score(mask_true.flatten(), mask_pred.flatten(), \n",
    "                               zero_division=0)\n",
    "            return iou\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_accuracy(mask_pred, mask_true):\n",
    "        \"\"\"\n",
    "        Calcule l'Accuracy (pixels correctement classifiés).\n",
    "        \n",
    "        Accuracy = |Pixels corrects| / |Total pixels|\n",
    "        \n",
    "        Args:\n",
    "            mask_pred (np.ndarray): Masque prédiction binaire\n",
    "            mask_true (np.ndarray): Masque vérité terrain binaire\n",
    "            \n",
    "        Returns:\n",
    "            float: Score Accuracy entre 0 et 1\n",
    "        \"\"\"\n",
    "        try:\n",
    "            acc = accuracy_score(mask_true.flatten(), mask_pred.flatten())\n",
    "            return acc\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_f1_score(mask_pred, mask_true):\n",
    "        \"\"\"\n",
    "        Calcule le F1 Score (harmonic mean).\n",
    "        \n",
    "        F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "        \n",
    "        Args:\n",
    "            mask_pred (np.ndarray): Masque prédiction binaire\n",
    "            mask_true (np.ndarray): Masque vérité terrain binaire\n",
    "            \n",
    "        Returns:\n",
    "            float: Score F1 entre 0 et 1\n",
    "        \"\"\"\n",
    "        try:\n",
    "            f1 = f1_score(mask_true.flatten(), mask_pred.flatten(), \n",
    "                         zero_division=0)\n",
    "            return f1\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    # =========================================================================\n",
    "    # ÉVALUATION GLOBALE\n",
    "    # =========================================================================\n",
    "    \n",
    "    def display_official_metrics(self):\n",
    "        \"\"\"Affiche les métriques officielles du modèle HF.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"METRIQUES OFFICIELLES - MODELE HUGGING FACE\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nMODEL CARD:\")\n",
    "        print(f\"  Model ID:                  sayeed99/segformer_b3_clothes\")\n",
    "        print(f\"  Architecture:              SegFormer B3\")\n",
    "        print(f\"  Task:                      Image Segmentation\")\n",
    "        print(f\"  Dataset:                   mattmdjaga/human_parsing_dataset\")\n",
    "        print(f\"  License:                   MIT\")\n",
    "        print(f\"  Downloads (last month):    8,051\")\n",
    "        \n",
    "        print(f\"\\nMETRIQUES GLOBALES:\")\n",
    "        print(f\"  Mean Accuracy:             {self.OFFICIAL_OVERALL_METRICS['mean_accuracy']:.2%}\")\n",
    "        print(f\"  Mean IoU:                  {self.OFFICIAL_OVERALL_METRICS['mean_iou']:.2%}\")\n",
    "        print(f\"  Evaluation Loss:           {self.OFFICIAL_OVERALL_METRICS['evaluation_loss']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nPERFORMANCES PAR CLASSE (Top 5 - Meilleur IoU):\")\n",
    "        sorted_classes = sorted(self.OFFICIAL_METRICS_BY_CLASS.items(),\n",
    "                               key=lambda x: x[1][\"iou\"],\n",
    "                               reverse=True)[:5]\n",
    "        for class_id, metrics in sorted_classes:\n",
    "            print(f\"  {metrics['name']:15} (ID={class_id:2}) | Accuracy: {metrics['accuracy']:.2%} | IoU: {metrics['iou']:.2%}\")\n",
    "        \n",
    "        print(f\"\\nPERFORMANCES PAR CLASSE (Bottom 5 - Pire IoU):\")\n",
    "        worst_classes = sorted(self.OFFICIAL_METRICS_BY_CLASS.items(),\n",
    "                              key=lambda x: x[1][\"iou\"])[:5]\n",
    "        for class_id, metrics in worst_classes:\n",
    "            print(f\"  {metrics['name']:15} (ID={class_id:2}) | Accuracy: {metrics['accuracy']:.2%} | IoU: {metrics['iou']:.2%}\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    def display_evaluation_table(self):\n",
    "        \"\"\"Affiche le tableau complet des évaluations par classe.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"TABLEAU D'EVALUATION PAR CLASSE\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Créer dataframe\n",
    "        data = []\n",
    "        for class_id in sorted(self.OFFICIAL_METRICS_BY_CLASS.keys()):\n",
    "            metrics = self.OFFICIAL_METRICS_BY_CLASS[class_id]\n",
    "            data.append({\n",
    "                \"Label ID\": class_id,\n",
    "                \"Classe\": metrics[\"name\"],\n",
    "                \"Accuracy\": f\"{metrics['accuracy']:.2%}\",\n",
    "                \"IoU\": f\"{metrics['iou']:.2%}\",\n",
    "                \"Performance\": \"Excellent\" if metrics[\"iou\"] >= 0.80 \n",
    "                              else \"Bon\" if metrics[\"iou\"] >= 0.60\n",
    "                              else \"Moyen\" if metrics[\"iou\"] >= 0.30\n",
    "                              else \"Faible\"\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # ANALYSE DE PERFORMANCE\n",
    "    # =========================================================================\n",
    "    \n",
    "    def display_performance_analysis(self):\n",
    "        \"\"\"Affiche une analyse détaillée des performances.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ANALYSE DETAILLEE DE PERFORMANCE\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Grouper par catégories de performance\n",
    "        excellent = []\n",
    "        good = []\n",
    "        average = []\n",
    "        weak = []\n",
    "        \n",
    "        for class_id, metrics in self.OFFICIAL_METRICS_BY_CLASS.items():\n",
    "            iou = metrics[\"iou\"]\n",
    "            if iou >= 0.80:\n",
    "                excellent.append((metrics[\"name\"], iou))\n",
    "            elif iou >= 0.60:\n",
    "                good.append((metrics[\"name\"], iou))\n",
    "            elif iou >= 0.30:\n",
    "                average.append((metrics[\"name\"], iou))\n",
    "            else:\n",
    "                weak.append((metrics[\"name\"], iou))\n",
    "        \n",
    "        print(f\"\\nPERFORMANCE EXCELLENTE (IoU >= 0.80):\")\n",
    "        print(f\"  Nombre de classes: {len(excellent)}/18\")\n",
    "        for name, iou in sorted(excellent, key=lambda x: x[1], reverse=True):\n",
    "            print(f\"    {name:20} IoU: {iou:.2%}\")\n",
    "        \n",
    "        print(f\"\\nBONNE PERFORMANCE (0.60 <= IoU < 0.80):\")\n",
    "        print(f\"  Nombre de classes: {len(good)}/18\")\n",
    "        for name, iou in sorted(good, key=lambda x: x[1], reverse=True):\n",
    "            print(f\"    {name:20} IoU: {iou:.2%}\")\n",
    "        \n",
    "        print(f\"\\nPERFORMANCE MOYENNE (0.30 <= IoU < 0.60):\")\n",
    "        print(f\"  Nombre de classes: {len(average)}/18\")\n",
    "        for name, iou in sorted(average, key=lambda x: x[1], reverse=True):\n",
    "            print(f\"    {name:20} IoU: {iou:.2%}\")\n",
    "        \n",
    "        print(f\"\\nPERFORMANCE FAIBLE (IoU < 0.30):\")\n",
    "        print(f\"  Nombre de classes: {len(weak)}/18\")\n",
    "        for name, iou in sorted(weak, key=lambda x: x[1], reverse=True):\n",
    "            print(f\"    {name:20} IoU: {iou:.2%}\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # MATRICE DE CONFUSION CONCEPTUELLE\n",
    "    # =========================================================================\n",
    "    \n",
    "    def display_confusion_analysis(self):\n",
    "        \"\"\"Affiche une analyse des classes confondues.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ANALYSE DES CONFUSIONS PROBABLES\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nCLASSES FREQUEMMENT CONFONDUES (faible IoU):\")\n",
    "        print(f\"\\n1. Ceinture (Belt) - IoU: 0.30\")\n",
    "        print(f\"   Raisons possibles:\")\n",
    "        print(f\"     - Classe tres petite (peu de pixels)\")\n",
    "        print(f\"     - Souvent confondue avec le haut (Upper-clothes)\")\n",
    "        print(f\"     - Variation visuelle importante\")\n",
    "        \n",
    "        print(f\"\\n2. Echarpe (Scarf) - IoU: 0.29\")\n",
    "        print(f\"   Raisons possibles:\")\n",
    "        print(f\"     - Classe minoritaire dans le dataset\")\n",
    "        print(f\"     - Segmentation difficile (formes variables)\")\n",
    "        print(f\"     - Souvent confondue avec les cheveux (Hair)\")\n",
    "        \n",
    "        print(f\"\\n3. Robe (Dress) - IoU: 0.55\")\n",
    "        print(f\"   Raisons possibles:\")\n",
    "        print(f\"     - Classe ambigue (peut ressembler à un haut + jupe)\")\n",
    "        print(f\"     - Variations de longueur importantes\")\n",
    "        \n",
    "        print(f\"\\nCLASSES BIEN SEGMENTEES (bon IoU):\")\n",
    "        print(f\"\\n1. Fond (Background) - IoU: 0.99\")\n",
    "        print(f\"   Force: Classe majoritaire, bien definie\")\n",
    "        \n",
    "        print(f\"\\n2. Visage (Face) - IoU: 0.85\")\n",
    "        print(f\"   Force: Texture distincte, bien identifiable\")\n",
    "        \n",
    "        print(f\"\\n3. Pantalon (Pants) - IoU: 0.84\")\n",
    "        print(f\"   Force: Classe courante, distincte\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RECOMMANDATIONS D'AMÉLIORATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    def display_improvement_recommendations(self):\n",
    "        \"\"\"Affiche les recommandations pour améliorer le modèle.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RECOMMANDATIONS D'AMELIORATION\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nPOUR LES CLASSES FAIBLES (IoU < 0.60):\")\n",
    "        \n",
    "        print(f\"\\n1. Ceinture (Belt) - Priorite HAUTE:\")\n",
    "        print(f\"   Actions recommandees:\")\n",
    "        print(f\"     - Augmenter les donnees d'entrainement pour cette classe\")\n",
    "        print(f\"     - Utiliser data augmentation specifique\")\n",
    "        print(f\"     - Revoir les labels (peut-etre confondus)\")\n",
    "        print(f\"     - Ajuster les poids de classe (class weighting)\")\n",
    "        \n",
    "        print(f\"\\n2. Echarpe (Scarf) - Priorite HAUTE:\")\n",
    "        print(f\"   Actions recommandees:\")\n",
    "        print(f\"     - Collecter plus d'exemples d'echarpes\")\n",
    "        print(f\"     - Augmenter le poids de cette classe\")\n",
    "        print(f\"     - Envisager une fine-tuning specifique\")\n",
    "        \n",
    "        print(f\"\\n3. Robe (Dress) - Priorite MOYENNE:\")\n",
    "        print(f\"   Actions recommandees:\")\n",
    "        print(f\"     - Post-processing: regles heuristiques\")\n",
    "        print(f\"     - Combiner avec detection de motifs\")\n",
    "        \n",
    "        print(f\"\\nSTRATEGIES GENERALES D'AMELIORATION:\")\n",
    "        print(f\"  - Augmenter la resolution des images d'entrainement\")\n",
    "        print(f\"  - Implémenter un post-processing morphologique\")\n",
    "        print(f\"  - Utiliser un ensemble (ensemble learning)\")\n",
    "        print(f\"  - Faire une fine-tuning sur des donnees specifiques\")\n",
    "        print(f\"  - Augmenter la capacite du modele (B4 ou B5)\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RAPPORT SYNTHÉTIQUE\n",
    "    # =========================================================================\n",
    "    \n",
    "    def display_complete_evaluation_report(self):\n",
    "        \"\"\"Affiche le rapport d'évaluation complet.\"\"\"\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"RAPPORT D'EVALUATION COMPLET DU MODELE\")\n",
    "        print(\"SegFormer B3 Clothes - sayeed99/segformer_b3_clothes\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Afficher toutes les sections\n",
    "        self.display_official_metrics()\n",
    "        self.display_evaluation_table()\n",
    "        self.display_performance_analysis()\n",
    "        self.display_confusion_analysis()\n",
    "        self.display_improvement_recommendations()\n",
    "        \n",
    "        # Résumé final\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RESUME EXECUTIF\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nEtat global du modele:\")\n",
    "        print(f\"  Accuracy moyenne:          80.0%\")\n",
    "        print(f\"  IoU moyenne:               69.0%\")\n",
    "        print(f\"  Nombre de classes:         18\")\n",
    "        print(f\"  Classes excellentes:       7/18 (39%)\")\n",
    "        print(f\"  Classes en difficulte:     4/18 (22%)\")\n",
    "        \n",
    "        print(f\"\\nConclude:\")\n",
    "        print(f\"  Le modele SegFormer B3 presente une performance solide\")\n",
    "        print(f\"  pour la majorite des vetements. Les axes d'amelioration\")\n",
    "        print(f\"  prioritaires sont les accessoires (ceinture, echarpe)\")\n",
    "        print(f\"  et certains vetements ambigus (robe).\")\n",
    "        print(f\"\\n  Utilisation recommandee: Production avec care sur\")\n",
    "        print(f\"  les classes faibles. Fine-tuning recommande pour\")\n",
    "        print(f\"  applications specifiques.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Creer l'évaluateur\n",
    "    evaluator = ModelEvaluator()\n",
    "    \n",
    "    # Afficher le rapport complet d'évaluation\n",
    "    evaluator.display_complete_evaluation_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0501634a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e896db0",
   "metadata": {},
   "source": [
    "# 8. Estimation des couts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6978c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ESTIMATION DE CHIFFRAGE FORMALISÉE - 1 IMAGE vs 50 EN BATCH\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Estimation de Chiffrage du Projet de Segmentation de Vêtements\n",
    "Modèle: sayeed99/segformer_b3_clothes\n",
    "Comparaison: 1 Image Seule vs 50 Images en Batch\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class EstimationChiffrage:\n",
    "    \"\"\"\n",
    "    Classe pour formaliser l'estimation de chiffrage en 3 dimensions.\n",
    "    Basée sur les tarifs HF officiels et les métriques du modèle.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_images=50):\n",
    "        \"\"\"\n",
    "        Initialise l'estimation.\n",
    "        \n",
    "        Args:\n",
    "            num_images (int): Nombre d'images à traiter\n",
    "        \"\"\"\n",
    "        self.num_images = num_images\n",
    "        self.model_id = \"sayeed99/segformer_b3_clothes\"\n",
    "        self.date_estimation = datetime.now()\n",
    "        \n",
    "        # Métriques officielles du modèle\n",
    "        self.model_metrics = {\n",
    "            \"mean_iou\": 0.69,\n",
    "            \"mean_accuracy\": 0.80,\n",
    "            \"evaluation_loss\": 0.15,\n",
    "        }\n",
    "        \n",
    "        # Tarifs Hugging Face\n",
    "        self.hf_pricing = {\n",
    "            \"gpu_compute_per_second\": 0.00008,\n",
    "            \"storage_per_gb_month\": 0.023,\n",
    "            \"bandwidth_per_gb\": 0.12,\n",
    "        }\n",
    "        \n",
    "        # Parametres temporels\n",
    "        self.timing_params = {\n",
    "            \"api_call_per_image_seconds\": 2.5,\n",
    "            \"network_overhead_per_image\": 1.0,\n",
    "            \"rate_limit_delay_single\": 0.5,  # Pas de delai important pour 1 image\n",
    "            \"rate_limit_delay_batch\": 1.0,   # Delai entre chaque appel en batch\n",
    "        }\n",
    "    \n",
    "    def calculate_timing_and_costs(self, scenario=\"batch\"):\n",
    "        \"\"\"\n",
    "        Calcule temps et coûts selon le scénario.\n",
    "        \n",
    "        Args:\n",
    "            scenario (str): \"single\" pour 1 image, \"batch\" pour batch\n",
    "            \n",
    "        Returns:\n",
    "            dict: Données temporelles et financières\n",
    "        \"\"\"\n",
    "        if scenario == \"single\":\n",
    "            rate_limit_delay = self.timing_params[\"rate_limit_delay_single\"]\n",
    "        else:\n",
    "            rate_limit_delay = self.timing_params[\"rate_limit_delay_batch\"]\n",
    "        \n",
    "        # Temps par appel\n",
    "        time_per_call = (self.timing_params[\"api_call_per_image_seconds\"] +\n",
    "                        self.timing_params[\"network_overhead_per_image\"] +\n",
    "                        rate_limit_delay)\n",
    "        \n",
    "        total_inference_seconds = self.num_images * time_per_call\n",
    "        \n",
    "        # Coûts\n",
    "        cost_api = total_inference_seconds * self.hf_pricing[\"gpu_compute_per_second\"]\n",
    "        storage_gb = (self.num_images * 2) / 1024\n",
    "        cost_storage = storage_gb * self.hf_pricing[\"storage_per_gb_month\"]\n",
    "        bandwidth_gb = (self.num_images * 4) / 1024\n",
    "        cost_bandwidth = bandwidth_gb * self.hf_pricing[\"bandwidth_per_gb\"]\n",
    "        total_cost = cost_api + cost_storage + cost_bandwidth\n",
    "        \n",
    "        return {\n",
    "            \"images\": self.num_images,\n",
    "            \"time_per_call_seconds\": time_per_call,\n",
    "            \"total_seconds\": total_inference_seconds,\n",
    "            \"total_minutes\": total_inference_seconds / 60,\n",
    "            \"total_hours\": total_inference_seconds / 3600,\n",
    "            \"cost_api\": cost_api,\n",
    "            \"cost_storage\": cost_storage,\n",
    "            \"cost_bandwidth\": cost_bandwidth,\n",
    "            \"total_cost\": total_cost,\n",
    "            \"cost_per_image\": total_cost / self.num_images,\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ESTIMATION 1 IMAGE SEULE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. ESTIMATION CHIFFRAGE - 1 IMAGE SEULE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "estimation_1 = EstimationChiffrage(num_images=1)\n",
    "data_1 = estimation_1.calculate_timing_and_costs(scenario=\"single\")\n",
    "\n",
    "print(f\"\\nTEMPS:\")\n",
    "print(f\"  Secondes:                   {data_1['total_seconds']:.1f} sec\")\n",
    "print(f\"  Minutes:                    {data_1['total_minutes']:.2f} min\")\n",
    "\n",
    "print(f\"\\nCOUTS (Tarifs HF):\")\n",
    "print(f\"  API Inference:              ${data_1['cost_api']:.6f}\")\n",
    "print(f\"  Stockage:                   ${data_1['cost_storage']:.6f}\")\n",
    "print(f\"  Bandwidth:                  ${data_1['cost_bandwidth']:.6f}\")\n",
    "print(f\"  Total:                      ${data_1['total_cost']:.6f}\")\n",
    "\n",
    "print(f\"\\nCREDITS GRATUITS:\")\n",
    "print(f\"  Free User (0.10/mois):      COUVERT (cout < 0.10)\")\n",
    "print(f\"  Pro User (2.00/mois):       COUVERT (cout < 2.00)\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ESTIMATION 50 IMAGES EN BATCH\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. ESTIMATION CHIFFRAGE - 50 IMAGES EN BATCH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "estimation_50 = EstimationChiffrage(num_images=50)\n",
    "data_50 = estimation_50.calculate_timing_and_costs(scenario=\"batch\")\n",
    "\n",
    "print(f\"\\nTEMPS:\")\n",
    "print(f\"  Secondes:                   {data_50['total_seconds']:.1f} sec\")\n",
    "print(f\"  Minutes:                    {data_50['total_minutes']:.2f} min\")\n",
    "print(f\"  Heures:                     {data_50['total_hours']:.3f} h\")\n",
    "\n",
    "print(f\"\\nCOUTS (Tarifs HF):\")\n",
    "print(f\"  API Inference:              ${data_50['cost_api']:.6f}\")\n",
    "print(f\"  Stockage:                   ${data_50['cost_storage']:.6f}\")\n",
    "print(f\"  Bandwidth:                  ${data_50['cost_bandwidth']:.6f}\")\n",
    "print(f\"  Total:                      ${data_50['total_cost']:.6f}\")\n",
    "\n",
    "print(f\"\\nCREDITS GRATUITS:\")\n",
    "print(f\"  Free User (0.10/mois):      COUVERT (cout < 0.10)\")\n",
    "print(f\"  Pro User (2.00/mois):       COUVERT (cout < 2.00)\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SCENARIO COMPARATIF: 50 Images en 1 par 1 vs 50 en Batch\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. COMPARAISON SCENARIO - 50 IMAGES: 1 PAR 1 vs EN BATCH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Scenario 1: 50 images traitées 1 par 1\n",
    "estimation_50_solo = EstimationChiffrage(num_images=50)\n",
    "data_50_solo = estimation_50_solo.calculate_timing_and_costs(scenario=\"single\")\n",
    "\n",
    "# Scenario 2: 50 images en batch\n",
    "estimation_50_batch = EstimationChiffrage(num_images=50)\n",
    "data_50_batch = estimation_50_batch.calculate_timing_and_costs(scenario=\"batch\")\n",
    "\n",
    "# Créer tableau comparatif\n",
    "comparison_data = {\n",
    "    \"Metrique\": [\n",
    "        \"Nombre d'images\",\n",
    "        \"Temps par appel (sec)\",\n",
    "        \"Temps total (sec)\",\n",
    "        \"Temps total (min)\",\n",
    "        \"Temps total (heures)\",\n",
    "        \"\",\n",
    "        \"Coût API (USD)\",\n",
    "        \"Coût Stockage (USD)\",\n",
    "        \"Coût Bandwidth (USD)\",\n",
    "        \"Coût Total (USD)\",\n",
    "        \"Coût par image (USD)\",\n",
    "        \"\",\n",
    "        \"Gain de temps (%)\",\n",
    "        \"Economies (USD)\",\n",
    "        \"Economies (%)\",\n",
    "    ],\n",
    "    \"50 Images 1 par 1\": [\n",
    "        str(data_50_solo[\"images\"]),\n",
    "        f\"{data_50_solo['time_per_call_seconds']:.1f}\",\n",
    "        f\"{data_50_solo['total_seconds']:.1f}\",\n",
    "        f\"{data_50_solo['total_minutes']:.1f}\",\n",
    "        f\"{data_50_solo['total_hours']:.3f}\",\n",
    "        \"\",\n",
    "        f\"${data_50_solo['cost_api']:.6f}\",\n",
    "        f\"${data_50_solo['cost_storage']:.6f}\",\n",
    "        f\"${data_50_solo['cost_bandwidth']:.6f}\",\n",
    "        f\"${data_50_solo['total_cost']:.6f}\",\n",
    "        f\"${data_50_solo['cost_per_image']:.6f}\",\n",
    "        \"\",\n",
    "        \"-\",\n",
    "        \"-\",\n",
    "        \"-\",\n",
    "    ],\n",
    "    \"50 Images Batch\": [\n",
    "        str(data_50_batch[\"images\"]),\n",
    "        f\"{data_50_batch['time_per_call_seconds']:.1f}\",\n",
    "        f\"{data_50_batch['total_seconds']:.1f}\",\n",
    "        f\"{data_50_batch['total_minutes']:.1f}\",\n",
    "        f\"{data_50_batch['total_hours']:.3f}\",\n",
    "        \"\",\n",
    "        f\"${data_50_batch['cost_api']:.6f}\",\n",
    "        f\"${data_50_batch['cost_storage']:.6f}\",\n",
    "        f\"${data_50_batch['cost_bandwidth']:.6f}\",\n",
    "        f\"${data_50_batch['total_cost']:.6f}\",\n",
    "        f\"${data_50_batch['cost_per_image']:.6f}\",\n",
    "        \"\",\n",
    "        f\"{((data_50_solo['total_seconds']-data_50_batch['total_seconds'])/data_50_solo['total_seconds']*100):.1f}%\",\n",
    "        f\"${data_50_solo['total_cost']-data_50_batch['total_cost']:.6f}\",\n",
    "        f\"{((data_50_solo['total_cost']-data_50_batch['total_cost'])/data_50_solo['total_cost']*100):.1f}%\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Afficher le tableau\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Analyse\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSE COMPARATIVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "gain_temps = ((data_50_solo['total_seconds']-data_50_batch['total_seconds'])/data_50_solo['total_seconds']*100)\n",
    "economies = data_50_solo['total_cost']-data_50_batch['total_cost']\n",
    "economies_pct = (economies/data_50_solo['total_cost']*100)\n",
    "\n",
    "print(f\"\\nGAIN DE TEMPS:\")\n",
    "print(f\"  1 par 1:                    {data_50_solo['total_minutes']:.1f} minutes\")\n",
    "print(f\"  En batch:                   {data_50_batch['total_minutes']:.1f} minutes\")\n",
    "print(f\"  Gain:                       {data_50_solo['total_minutes']-data_50_batch['total_minutes']:.1f} minutes\")\n",
    "print(f\"  Gain en pourcentage:        {gain_temps:.1f}%\")\n",
    "\n",
    "print(f\"\\nECONOMIES FINANCIERES:\")\n",
    "print(f\"  Cout 1 par 1:               ${data_50_solo['total_cost']:.6f}\")\n",
    "print(f\"  Cout en batch:              ${data_50_batch['total_cost']:.6f}\")\n",
    "print(f\"  Economies:                  ${economies:.6f}\")\n",
    "print(f\"  Economies en pourcentage:   {economies_pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nCONCLUSION:\")\n",
    "if gain_temps > 0:\n",
    "    print(f\"  Traiter 50 images en batch est plus rapide de {gain_temps:.1f}%\")\n",
    "    print(f\"  et moins cher de {economies_pct:.1f}%\")\n",
    "else:\n",
    "    print(f\"  Les deux approches ont des performances similaires\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TABLEAU SYNTHÉTIQUE FINAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLEAU SYNTHÉTIQUE - RÉSUMÉ GLOBAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = {\n",
    "    \"Scenario\": [\n",
    "        \"1 Image seule\",\n",
    "        \"50 Images 1 par 1\",\n",
    "        \"50 Images en Batch\",\n",
    "    ],\n",
    "    \"Temps (sec)\": [\n",
    "        f\"{data_1['total_seconds']:.1f}\",\n",
    "        f\"{data_50_solo['total_seconds']:.1f}\",\n",
    "        f\"{data_50_batch['total_seconds']:.1f}\",\n",
    "    ],\n",
    "    \"Temps (min)\": [\n",
    "        f\"{data_1['total_minutes']:.2f}\",\n",
    "        f\"{data_50_solo['total_minutes']:.1f}\",\n",
    "        f\"{data_50_batch['total_minutes']:.1f}\",\n",
    "    ],\n",
    "    \"Cout (USD)\": [\n",
    "        f\"${data_1['total_cost']:.6f}\",\n",
    "        f\"${data_50_solo['total_cost']:.6f}\",\n",
    "        f\"${data_50_batch['total_cost']:.6f}\",\n",
    "    ],\n",
    "    \"Cout/Image (USD)\": [\n",
    "        f\"${data_1['cost_per_image']:.6f}\",\n",
    "        f\"${data_50_solo['cost_per_image']:.6f}\",\n",
    "        f\"${data_50_batch['cost_per_image']:.6f}\",\n",
    "    ],\n",
    "    \"Efficacite\": [\n",
    "        \"Ref\",\n",
    "        \"Moins efficace\",\n",
    "        \"Plus efficace\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(\"\\n\")\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49f044",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "907a8544",
   "metadata": {},
   "source": [
    "# - FIN - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f7e3d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet2-py3.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
